services:
  # FastAPI Backend
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    container_name: ser-backend
    ports:
      - "8000:8000"
    volumes:
      # Cache HuggingFace models to avoid re-downloading
      - huggingface-cache:/root/.cache/huggingface
    environment:
      - PYTHONUNBUFFERED=1
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')",
        ]
      interval: 10s
      timeout: 10s
      retries: 20
      start_period: 60s # Model loads faster when cached
    restart: unless-stopped

  # Streamlit Frontend
  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile
    container_name: ser-frontend
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://backend:8000
    depends_on:
      backend:
        condition: service_healthy
    restart: unless-stopped

volumes:
  huggingface-cache:
    name: ser-huggingface-cache
